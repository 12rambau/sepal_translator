{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d38aee0e",
   "metadata": {},
   "source": [
    "found here : https://github.com/ImperialNLP/NLPLabs/blob/c724834960345085690802233966682bc3321723/lab06/lab06_solutions.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "410fc697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading train.lc.norm.tok.en\n",
      "Downloading train.lc.norm.tok.de\n",
      "Downloading train.lc.norm.tok.fr\n",
      "Downloading val.lc.norm.tok.en\n",
      "Downloading val.lc.norm.tok.de\n",
      "Downloading val.lc.norm.tok.fr\n",
      "Downloading test_2016_flickr.lc.norm.tok.en\n",
      "Downloading test_2016_flickr.lc.norm.tok.de\n",
      "Downloading test_2016_flickr.lc.norm.tok.fr\n",
      "\n",
      "     1\ttwo young , white males are outside near many bushes .\n",
      "     2\tseveral men in hard hats are operating a giant pulley system .\n",
      "     3\ta little girl climbing into a wooden playhouse .\n",
      "     4\ta man in a blue shirt is standing on a ladder cleaning a window .\n",
      "     5\ttwo men are at the stove preparing food .\n",
      "     6\ta man in green holds a guitar while the other man observes his shirt .\n",
      "     7\ta man is smiling at a stuffed lion\n",
      "     8\ta trendy girl talking on her cellphone while gliding slowly down the street .\n",
      "     9\ta woman with a large purse is walking by a gate .\n",
      "    10\tboys dancing on poles in the middle of the night .\n",
      "\n",
      "     1\tdeux jeunes hommes blancs sont dehors près de buissons .\n",
      "     2\tplusieurs hommes en casque font fonctionner un système de poulies géant .\n",
      "     3\tune petite fille grimpe dans une maisonnette en bois .\n",
      "     4\tun homme dans une chemise bleue se tient sur une échelle pour nettoyer une fenêtre .\n",
      "     5\tdeux hommes aux fourneaux préparent à manger .\n",
      "     6\tun homme en vert tient une guitare tandis qu&apos; un autre homme observe sa chemise .\n",
      "     7\tun homme sourit à un ours en peluche .\n",
      "     8\tune fille branchée parle à son portable tout en glissant lentement dans la rue .\n",
      "     9\tune femme avec un gros sac passe par une porte .\n",
      "    10\tdes garçons dansent sur des barres au milieu de la nuit .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "# Download the corpus\n",
    "URL=\"https://raw.githubusercontent.com/multi30k/dataset/master/data/task1/tok\"\n",
    "\n",
    "#cd data\n",
    "\n",
    "for split in \"train\" \"val\" \"test_2016_flickr\"; do\n",
    "    for lang in en de fr; do\n",
    "        fname=\"${split}.lc.norm.tok.${lang}\"\n",
    "        if [ ! -f $fname ]; then\n",
    "            echo \"Downloading $fname\"\n",
    "            wget -q \"${URL}/$fname\" -O \"${split/_2016_flickr/}.${lang}\"\n",
    "        fi\n",
    "    done\n",
    "done\n",
    "echo \n",
    "\n",
    "# Print the first 10 lines with line numbers of \n",
    "# the English and French training data\n",
    "cat -n train.en | head -n10\n",
    "echo\n",
    "cat -n train.fr | head -n10\n",
    "echo\n",
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "742fa8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "390f9dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Multi30K:\n",
    "    \"\"\"A dataset wrapper for Multi30K.\"\"\"\n",
    "    def __init__(self, tokenizer, src_file, trg_file):\n",
    "\n",
    "        self.tokenizer = tokenizer\n",
    "    \n",
    "        self.src_sents, self.trg_sents = self.read_sentences(src_file, trg_file)\n",
    "\n",
    "    def read_sentences(self, src_file, trg_file):\n",
    "        src_sents = []\n",
    "        trg_sents = []\n",
    "\n",
    "        # Read source side\n",
    "        with open(src_file) as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                src_sents.append(line) \n",
    "            \n",
    "        # Read target side\n",
    "        with open(trg_file) as f:\n",
    "            for line in f:\n",
    "                line = line.strip()\n",
    "                trg_sents.append(line)\n",
    "\n",
    "        assert len(src_sents) == len(trg_sents), \"Files are not aligned!\"\n",
    "        return src_sents, trg_sents\n",
    "    \n",
    "    def collate_fn(self, idx):\n",
    "        src_texts = [self.src_sents[i] for i in idx]\n",
    "        trg_texts = [self.trg_sents[i] for i in idx]\n",
    "        \n",
    "        output = self.tokenizer.prepare_seq2seq_batch(src_texts=src_texts, \n",
    "                                                      tgt_texts=trg_texts, \n",
    "                                                      max_length=128, \n",
    "                                                      max_target_length=128,\n",
    "                                                      return_tensors='pt',\n",
    "                                                      truncation=True)\n",
    "        return output\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.src_sents)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df2661e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9b897db4e374edea810eb6bf30d6c30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1335.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff53dd574e894d819b848e2026614f71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=297928209.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MarianMTModel(\n",
       "  (model): MarianModel(\n",
       "    (shared): Embedding(58101, 512, padding_idx=58100)\n",
       "    (encoder): MarianEncoder(\n",
       "      (embed_tokens): Embedding(58101, 512, padding_idx=58100)\n",
       "      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n",
       "      (layers): ModuleList(\n",
       "        (0): MarianEncoderLayer(\n",
       "          (self_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): MarianEncoderLayer(\n",
       "          (self_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): MarianEncoderLayer(\n",
       "          (self_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): MarianEncoderLayer(\n",
       "          (self_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): MarianEncoderLayer(\n",
       "          (self_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): MarianEncoderLayer(\n",
       "          (self_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (decoder): MarianDecoder(\n",
       "      (embed_tokens): Embedding(58101, 512, padding_idx=58100)\n",
       "      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n",
       "      (layers): ModuleList(\n",
       "        (0): MarianDecoderLayer(\n",
       "          (self_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): MarianDecoderLayer(\n",
       "          (self_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): MarianDecoderLayer(\n",
       "          (self_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): MarianDecoderLayer(\n",
       "          (self_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): MarianDecoderLayer(\n",
       "          (self_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): MarianDecoderLayer(\n",
       "          (self_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): MarianAttention(\n",
       "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=58101, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import EncoderDecoderModel, MarianMTModel, MarianTokenizer, BartModel, BartConfig, BertConfig, BartForCausalLM,Trainer,TrainingArguments\n",
    "model = MarianMTModel.from_pretrained('Helsinki-NLP/opus-mt-en-de')\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74283685",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_mt():\n",
    "    \n",
    "    ## QUESTION 5 ##\n",
    "\n",
    "    mt_tokenizer = MarianTokenizer.from_pretrained('Helsinki-NLP/opus-mt-en-de')\n",
    "    mt_dataset = Multi30K(mt_tokenizer, 'train.en', 'train.de')\n",
    "    mt_test_dataset = Multi30K(mt_tokenizer, 'test.en', 'test.de')\n",
    "    \n",
    "    model = MarianMTModel.from_pretrained('Helsinki-NLP/opus-mt-en-de')\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='./experiment/mt',\n",
    "        learning_rate = 0.00005,\n",
    "        logging_steps= 5000,\n",
    "        save_steps = 10000,\n",
    "        num_train_epochs = 1,\n",
    "        per_device_train_batch_size=2\n",
    "    )\n",
    "    trainer = Trainer(\n",
    "        model=model,                         \n",
    "        args=training_args,                 \n",
    "        train_dataset=mt_dataset,                     \n",
    "        data_collator=mt_dataset.collate_fn\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "\n",
    "    ## when you already trained your model and want to start from a checkpoint\n",
    "    #trainer.train(\"./experiment/mt/checkpoint-40000\")\n",
    "\n",
    "    trainer.save_model('./models/mt_marianmt/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a161c973",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fffc7d424364f42ae71e2676599a354",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=768489.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "986057df00a247af9ab45b3d240ff4e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=796845.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd9997dfd3884b61b3d4c55e45a547f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1273232.0, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c549983d8da4f9296aa06f5914ab106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=42.0, style=ProgressStyle(description_w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abarthe/miniconda3/envs/nmt/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py:30: UserWarning: \n",
      "    There is an imbalance between your GPUs. You may want to exclude GPU 0 which\n",
      "    has less than 75% of the memory or cores of GPU 2. You can do so by setting\n",
      "    the device_ids argument to DataParallel, or by setting the CUDA_VISIBLE_DEVICES\n",
      "    environment variable.\n",
      "  warnings.warn(imbalance_warn.format(device_ids[min_pos], device_ids[max_pos]))\n",
      "/home/abarthe/miniconda3/envs/nmt/lib/python3.8/site-packages/transformers/tokenization_utils_base.py:3216: FutureWarning: `prepare_seq2seq_batch` is deprecated and will be removed in version 5 of 🤗 Transformers. Use the regular `__call__` method to prepare your inputs and the tokenizer under the `with_target_tokenizer` context manager to prepare your targets. See the documentation of your specific tokenizer for more details\n",
      "  warnings.warn(\n",
      "/home/abarthe/miniconda3/envs/nmt/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:65: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "        <style>\n",
       "            /* Turns off some styling */\n",
       "            progress {\n",
       "                /* gets rid of default border in Firefox and Opera. */\n",
       "                border: none;\n",
       "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "                background-size: auto;\n",
       "            }\n",
       "        </style>\n",
       "      \n",
       "      <progress value='1450' max='1450' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1450/1450 22:51, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "main_mt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec19c88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sacrebleu\n",
    "\n",
    "def evaluate_mt(model,mt_tokenizer, mt_test_dataset):\n",
    "\n",
    "  bleu = []\n",
    "\n",
    "  model.eval()\n",
    "\n",
    "#   for file in tqdm(range(len(mt_test_dataset))):\n",
    "  for file in range(len(mt_test_dataset)):\n",
    "\n",
    "    src_text = mt_test_dataset.src_sents[file]\n",
    "    targ_text_origin = mt_test_dataset.trg_sents[file]\n",
    "\n",
    "    translated = model.generate(**mt_tokenizer.prepare_seq2seq_batch(src_text, return_tensors=\"pt\"))\n",
    "    translated_text = [mt_tokenizer.decode(t, skip_special_tokens=True) for t in translated]\n",
    "\n",
    "    bleu.append(sacrebleu.corpus_bleu(translated_text, targ_text_origin, force=True).score)\n",
    "\n",
    "  bleu = np.asarray(bleu)\n",
    "\n",
    "  return np.average(bleu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1c7ce8f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-73aa64394b7c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmt_test_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMulti30K\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmt_tokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test.en'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'test.de'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mbleu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmt_tokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmt_test_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbleu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-c9ff4aed12e0>\u001b[0m in \u001b[0;36mevaluate_mt\u001b[0;34m(model, mt_tokenizer, mt_test_dataset)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mbleu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msacrebleu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_bleu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranslated_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarg_text_origin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m   \u001b[0mbleu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbleu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbleu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "model = MarianMTModel.from_pretrained('./models/mt_marianmt/')\n",
    "\n",
    "mt_tokenizer = MarianTokenizer.from_pretrained('Helsinki-NLP/opus-mt-en-de')\n",
    "mt_test_dataset = Multi30K(mt_tokenizer, 'test.en', 'test.de')\n",
    "\n",
    "bleu = evaluate_mt(model,mt_tokenizer, mt_test_dataset)\n",
    "\n",
    "print(bleu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ace3f08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Multi30K at 0x7fe838894a90>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mt_test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed348fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
