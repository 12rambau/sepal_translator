{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c21b0bf5",
   "metadata": {},
   "source": [
    "found here : https://colab.research.google.com/github/vasudevgupta7/huggingface-tutorials/blob/main/translation_training.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32972160",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    MBartForConditionalGeneration, MBartTokenizer, \n",
    "    Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "  )\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d6ff5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rootdata = \"../data_test/parallel/\"\n",
    "data = []\n",
    "with open(rootdata+\"IITB.en-hi.en\") as f2, open(rootdata+\"IITB.en-hi.hi\") as f1:\n",
    "    for src, tgt in zip(f1, f2):\n",
    "      data.append(\n",
    "          {\n",
    "              \"translation\": {\n",
    "                  \"hi\": src.strip(),\n",
    "                  \"en\": tgt.strip()\n",
    "              }\n",
    "          }\n",
    "      )\n",
    "print(f'total size of data is {len(data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1a9733",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb58876d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab457742",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2df3e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting dataset into train, validation\n",
    "split = 0.2\n",
    "train_dataset, eval_dataset = random_split(data, lengths=[int((1-split)*len(data)), int(split*len(data))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40681ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining collator functioon for preparing batches on the fly ..\n",
    "def data_collator(features:list):\n",
    "    labels = [f[\"translation\"][\"en\"] for f in features]\n",
    "    inputs = [f[\"translation\"][\"hi\"] for f in features]\n",
    "\n",
    "    batch = tokenizer.prepare_seq2seq_batch(src_texts=inputs, src_lang=\"hi_IN\", tgt_lang=\"en_XX\", tgt_texts=labels, max_length=32, max_target_length=32)\n",
    "\n",
    "    for k in batch:\n",
    "        batch[k] = torch.tensor(batch[k])\n",
    "\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8822b6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import MarianMTModel, MarianTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2cb150",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiating model, tokenizer\n",
    "# model = MBartForConditionalGeneration.from_pretrained(\"facebook/mbart-large-cc25\")\n",
    "# tokenizer = MBartTokenizer.from_pretrained(\"facebook/mbart-large-cc25\")\n",
    "\n",
    "model_name = 'Helsinki-NLP/opus-mt-en-hi'\n",
    "model = MarianMTModel.from_pretrained(model_name)\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# defining training related arguments\n",
    "args = Seq2SeqTrainingArguments(output_dir=\"indic-mbart\",\n",
    "                        do_train=True,\n",
    "                        do_eval=True,\n",
    "                        evaluation_strategy=\"epoch\",\n",
    "                        per_device_train_batch_size=16,\n",
    "                        per_device_eval_batch_size=16,\n",
    "                        learning_rate=5e-5,\n",
    "                        num_train_epochs=2,\n",
    "                        logging_dir=\"/home/abarthe/.tensorboard_files/logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65d11179",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining trainer using ü§ó\n",
    "trainer = Seq2SeqTrainer(model=model, \n",
    "                args=args, \n",
    "                data_collator=data_collator, \n",
    "                train_dataset=train_dataset, \n",
    "                eval_dataset=eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9694041b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "52e086a1",
   "metadata": {},
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fc210a",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = \"‡§Ö‡§Ç‡§§‡§ø‡§Æ ‡§™‡•ç‡§∞‡§µ‡§ø‡§∑‡•ç‡§ü ‡§ò‡§ü‡§®‡§æ ‡§ï‡•ã ‡§π‡§æ‡§á‡§≤‡§æ‡§á‡§ü ‡§ï‡§∞‡•ã\"\n",
    "inputs_tokenized = tokenizer(inputs, return_tensors=\"pt\", padding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d338a8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.predict(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966cf096",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_model = \"finetuned/test\"\n",
    "trainer.save_model(ft_model)\n",
    "tokenizer.save_pretrained(ft_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e6bdce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import pipeline\n",
    "# model_id = \"vasudevgupta/mbart-iitb-hin-eng\"\n",
    "# translator = pipeline(\"translation_hi_to_en\", model=model_id, tokenizer=model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efb950c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trained = trainer.model\n",
    "tokenizer_trained = trainer.tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b550f682",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_trained.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7bad9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "translated = model_trained.generate(**tokenizer_trained(inputs, return_tensors=\"pt\", padding=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419ccb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets see how our model performs\n",
    "inputs = \"‡§Ö‡§Ç‡§§‡§ø‡§Æ ‡§™‡•ç‡§∞‡§µ‡§ø‡§∑‡•ç‡§ü ‡§ò‡§ü‡§®‡§æ ‡§ï‡•ã ‡§π‡§æ‡§á‡§≤‡§æ‡§á‡§ü ‡§ï‡§∞‡•ã\"\n",
    "inputs_tokenized = tokenizer(inputs, return_tensors=\"pt\", padding=True)\n",
    "\n",
    "# translation = translator(inputs, return_text=True)\n",
    "# translation = [t[\"translation_text\"] for t in translation]\n",
    "# print(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b168cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf63b9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5400c4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "translator = pipeline(\"translation_hi_to_en\", model=trainer.model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a0d3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets see how our model performs\n",
    "inputs = \"‡§Ö‡§Ç‡§§‡§ø‡§Æ ‡§™‡•ç‡§∞‡§µ‡§ø‡§∑‡•ç‡§ü ‡§ò‡§ü‡§®‡§æ ‡§ï‡•ã ‡§π‡§æ‡§á‡§≤‡§æ‡§á‡§ü ‡§ï‡§∞‡•ã\"\n",
    "\n",
    "translation = translator(inputs, return_text=True)\n",
    "translation = [t[\"translation_text\"] for t in translation]\n",
    "print(translation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abbe7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5283eed4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
